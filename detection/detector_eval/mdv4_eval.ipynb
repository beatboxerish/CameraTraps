{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'  # default is ‘last_expr’\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/siyuyang/Source/Repos/GitHub_MSFT/CameraTraps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# requires the TF Object Detection API be installed\n",
    "from detection.detector_eval import detector_eval  # detector_eval.py functions in this directory\n",
    "from visualization import visualization_utils as viz_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MegaDetector v4 experiments - evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdv4boxes_label_path = '/Users/siyuyang/OneDrive - Microsoft/AI4Earth/CameraTrap/Databases/query_results/bboxes_20200123.json'\n",
    "\n",
    "res_dir = '/Users/siyuyang/Source/temp_data/CameraTrap/megadetector_v4/mdv4_results'\n",
    "test_set_res_paths = {\n",
    "    'mdv4_baseline_run12_step520k': '5247_detections_mdv4_baseline_run12_step520k_on_test_20200310001011.json',\n",
    "    'mdv4_baseline_run5_step735902': '8542_detections_mdv4_baseline_run5_step735902_on_test_20200310014304.json',\n",
    "    'mdv3': '8583_detections_mdv3_on_test_20200310002010.json',\n",
    "    'mdv2': '1983_detections_mdv2_on_test_20200310004514.json'\n",
    "}\n",
    "\n",
    "out_dir = '/Users/siyuyang/OneDrive - Microsoft/AI4Earth/CameraTrap/MegaDetectorEval/megadetectorv4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching label and predicted boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdv4_baseline_run12_step520k, number of results: 17023\n",
      "mdv4_baseline_run5_step735902, number of results: 17023\n",
      "mdv3, number of results: 17023\n",
      "mdv2, number of results: 17023\n"
     ]
    }
   ],
   "source": [
    "test_set_res = {}\n",
    "for checkpoint_name, out_name in test_set_res_paths.items():\n",
    "    with open(os.path.join(res_dir, out_name)) as f:\n",
    "        test_set_res[checkpoint_name] = json.load(f)['images']\n",
    "    print('{}, number of results: {}'.format(checkpoint_name, len(test_set_res[checkpoint_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numerical IDs from output files of the API, and names in the MegaDB\n",
    "label_map_name_to_id = {\n",
    "    'animal': 1,\n",
    "    'person': 2,\n",
    "    'vehicle': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'mdv4_images/test/rspb_gola+899c8a74-3f14-11ea-b66d-9801a7a664ab.jpg',\n",
       " 'max_detection_conf': 1.0,\n",
       " 'detections': [{'category': '1',\n",
       "   'conf': 1.0,\n",
       "   'bbox': [0.0016, 0.2824, 0.2653, 0.3398]},\n",
       "  {'category': '1', 'conf': 0.068, 'bbox': [0.9802, 0.4392, 0.0177, 0.0373]},\n",
       "  {'category': '1', 'conf': 0.064, 'bbox': [0.9764, 0.4356, 0.0225, 0.0582]}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_res['mdv4_baseline_run12_step520k'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17023"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not used\n",
    "\n",
    "test_set = set([i['file'].split('/')[-1].split('.jpg')[0] for i in test_set_res['mdv4_baseline_run12_step520k']])\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mdv4boxes_label_path) as f:\n",
    "    mdv4boxes_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'bbox': [{'category': 'person', 'bbox': [0.7821, 0.6417, 0.2178, 0.3316]},\n",
       "  {'category': 'person', 'bbox': [0, 0.2614, 0.2018, 0.29]}],\n",
       " 'file': 'Day/2/IMAG0462 (7).JPG',\n",
       " 'dataset': 'peaceparks_201908_humans',\n",
       " 'location': '7',\n",
       " 'download_id': 'peaceparks_201908_humans+8896d576-3f14-11ea-b3bb-9801a7a664ab'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mdv4boxes_labels)\n",
    "mdv4boxes_labels[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17023\n"
     ]
    }
   ],
   "source": [
    "mdv4boxes_labels_dict = {}\n",
    "for i in mdv4boxes_labels:\n",
    "    if i['download_id'] in test_set:\n",
    "        mdv4boxes_labels_dict[i['download_id']] = i\n",
    "print(len(mdv4boxes_labels_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdv4_baseline_run12_step520k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 98/17023 [00:00<00:17, 975.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of per_image_gts is 17023, per_image_detections is 17023\n",
      "Running per-object analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17023/17023 [00:12<00:00, 1358.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing precision recall for each category...\n",
      "Number of ground truth in category 1 is 18505\n",
      "Number of ground truth in category 2 is 3185\n",
      "Number of ground truth in category 3 is 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17023 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_class average precision is 0.8837287615702089\n",
      "-----------\n",
      "mdv4_baseline_run5_step735902\n",
      "Lengths of per_image_gts is 17023, per_image_detections is 17023\n",
      "Running per-object analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17023/17023 [00:13<00:00, 1302.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing precision recall for each category...\n",
      "Number of ground truth in category 1 is 18505\n",
      "Number of ground truth in category 2 is 3185\n",
      "Number of ground truth in category 3 is 60\n",
      "one_class average precision is 0.8776877228745031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17023 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "mdv3\n",
      "Lengths of per_image_gts is 17023, per_image_detections is 17023\n",
      "Running per-object analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17023/17023 [00:12<00:00, 1367.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing precision recall for each category...\n",
      "Number of ground truth in category 1 is 18505\n",
      "Number of ground truth in category 2 is 3185\n",
      "Number of ground truth in category 3 is 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17023 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_class average precision is 0.833470328917\n",
      "-----------\n",
      "mdv2\n",
      "Lengths of per_image_gts is 17023, per_image_detections is 17023\n",
      "Running per-object analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17023/17023 [00:11<00:00, 1511.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing precision recall for each category...\n",
      "Number of ground truth in category 1 is 18505\n",
      "Number of ground truth in category 2 is 3185\n",
      "Number of ground truth in category 3 is 60\n",
      "one_class average precision is 0.6459082089541535\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "checkpoint_metrics = {}\n",
    "\n",
    "for checkpoint_name, detection_res in test_set_res.items():\n",
    "    print(checkpoint_name)\n",
    "    \n",
    "    per_image_gts, per_image_detections = detector_eval.get_per_image_gts_and_detections(\n",
    "        mdv4boxes_labels_dict, detection_res, label_map_name_to_id)\n",
    "        \n",
    "    print('Lengths of per_image_gts is {}, per_image_detections is {}'.format(\n",
    "        len(per_image_gts), len(per_image_detections)))\n",
    "    \n",
    "    per_cat_metrics = detector_eval.compute_precision_recall_bbox(per_image_detections, per_image_gts, 3, \n",
    "                                                    matching_iou_threshold=0.5)\n",
    "\n",
    "    checkpoint_metrics[checkpoint_name] = per_cat_metrics\n",
    "    print('one_class average precision is {}'.format(per_cat_metrics['one_class']['average_precision']))\n",
    "    print('-----------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score_threshold: 0.5\n",
      "1, total_tp: 15847, total_fp: 2936\n",
      "\n",
      "score_threshold: 0.8\n",
      "1, total_tp: 15337, total_fp: 1310\n",
      "\n",
      "score_threshold: 0.9\n",
      "1, total_tp: 14979, total_fp: 832\n",
      "\n",
      "score_threshold: 0.5\n",
      "2, total_tp: 2867, total_fp: 471\n",
      "\n",
      "score_threshold: 0.8\n",
      "2, total_tp: 2800, total_fp: 175\n",
      "\n",
      "score_threshold: 0.9\n",
      "2, total_tp: 2735, total_fp: 96\n",
      "\n",
      "score_threshold: 0.5\n",
      "3, total_tp: 53, total_fp: 38\n",
      "\n",
      "score_threshold: 0.8\n",
      "3, total_tp: 52, total_fp: 16\n",
      "\n",
      "score_threshold: 0.9\n",
      "3, total_tp: 50, total_fp: 10\n",
      "\n",
      "score_threshold: 0.5\n",
      "one_class, total_tp: 18767, total_fp: 3445\n",
      "\n",
      "score_threshold: 0.8\n",
      "one_class, total_tp: 18189, total_fp: 1501\n",
      "\n",
      "score_threshold: 0.9\n",
      "one_class, total_tp: 17764, total_fp: 938\n"
     ]
    }
   ],
   "source": [
    "for category, metrics in per_cat_metrics.items():\n",
    "    # _ = viz_utils.plot_precision_recall_curve(metrics['precision'], metrics['recall'], title=category)\n",
    "    \n",
    "    for score_threshold in [0.5, 0.8, 0.9]:\n",
    "        print('\\nscore_threshold: {}'.format(score_threshold))\n",
    "        total_tp = 0\n",
    "        total_fp = 0\n",
    "        for score, tp_fp in zip(metrics['scores'], metrics['tp_fp']):\n",
    "            if score > score_threshold:\n",
    "                if tp_fp == 1:\n",
    "                    total_tp += 1\n",
    "                else:\n",
    "                    total_fp += 1\n",
    "        print('{}, total_tp: {}, total_fp: {}'.format(category, total_tp, total_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cameratraps] *",
   "language": "python",
   "name": "conda-env-cameratraps-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
